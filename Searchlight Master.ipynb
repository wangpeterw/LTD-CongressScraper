{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searchlight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "import urllib\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize DataScience Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Speech Table\n",
    "speeches = Table().with_columns(\"speech_id\", make_array(), \n",
    "                                \"speaker_id\", make_array(), \n",
    "                                \"proceeding_id\", make_array(), \n",
    "                                \"topic_id\", make_array(), \n",
    "                                \"word_count\", make_array(), \n",
    "                                \"speech_text\", make_array(),\n",
    "                                'file_name', make_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>speech_id</th> <th>speaker_id</th> <th>proceeding_id</th> <th>topic_id</th> <th>word_count</th> <th>speech_text</th> <th>file_name</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "speech_id | speaker_id | proceeding_id | topic_id | word_count | speech_text | file_name"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Speaker Table\n",
    "speakers = Table().with_columns(\"speaker_id\", make_array(), \n",
    "                                \"first_name\", make_array(), \n",
    "                                \"last_name\", make_array(), \n",
    "                                \"type\" , make_array(),\n",
    "                                \"party\", make_array(), \n",
    "                                \"state\", make_array(), \n",
    "                                \"district\", make_array(),\n",
    "                                \"bio_guide_id\", make_array(),\n",
    "                                \"congress_id\", make_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>speaker_id</th> <th>first_name</th> <th>last_name</th> <th>type</th> <th>party</th> <th>state</th> <th>district</th> <th>bio_guide_id</th> <th>congress_id</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "speaker_id | first_name | last_name | type | party | state | district | bio_guide_id | congress_id"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics = Table().with_columns(\"topic_id\", make_array(), \n",
    "                                \"topic_name\", make_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>topic_id</th> <th>topic_name</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "topic_id | topic_name"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Proceedings Table\n",
    "proceedings = Table().with_columns(\"proceeding_id\", make_array(), \n",
    "                              \"date\", make_array(),\n",
    "                              \"title\", make_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>proceeding_id</th> <th>date</th> <th>title</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "proceeding_id | date | title"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proceedings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Initializing Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_space(regex):\n",
    "    return regex.group().replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sep_speech(string):\n",
    "    parse_file = ''\n",
    "    with open(string) as file:\n",
    "        for line in file:\n",
    "            parse_file += line\n",
    "    parse_file = parse_file.replace('\\n', '')\n",
    "#     parse_file = parse_file.replace('Mr. President', 'MrPresident')\n",
    "#     parse_file = parse_file.replace('Mr. Short', 'Mr.Short')\n",
    "    parse_file = re.sub('Mr. [A-Z][a-z]', remove_space, parse_file)\n",
    "    \n",
    "    split = re.split(r'Mr. |Ms. |Mrs. ', parse_file)\n",
    "    split.pop(0)\n",
    "    name_and_speech = make_array()\n",
    "    for i in np.arange(len(split)):\n",
    "        try:\n",
    "            lastname = re.match('[A-Z]*\\. ', split[i]).group(0)[:-2]\n",
    "            name_and_speech = np.append(name_and_speech, lastname)\n",
    "            value = re.sub('[A-Z]\\w*\\. ', '', split[i])\n",
    "            name_and_speech = np.append(name_and_speech, value)\n",
    "        except:\n",
    "            abcabcabc = 1\n",
    "    return name_and_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sep_date_from_file(file):\n",
    "    abcdef = re.findall('[0-9]{4}-[0-9]{2}-[0-9]{2}', file)\n",
    "    return re.split('-', abcdef[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_title(file_name):\n",
    "    parse_file = ''\n",
    "    with open(string) as file:\n",
    "        for line in file:\n",
    "            parse_file += line\n",
    "    parse_file = parse_file.replace('Mr. President', 'MrPresident')\n",
    "    title = re.findall('[A-Z \\'-]+[A-Z0-9-,\\. ]*[Continued]*\\\\n', parse_file)\n",
    "    return title[0].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mods Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAllExtensions(file):\n",
    "    handler = open(file).read()\n",
    "    soup = Soup(handler, \"lxml\")\n",
    "    return soup.find_all('extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_extensions = getAllExtensions(\"mastermods.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCongMemberExtension(extensions, last_name):\n",
    "    for extension in extensions:\n",
    "        ext = str(extension)\n",
    "        if last_name in ext:\n",
    "            return extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCongMemberExtensionFromFile(last_name, filename):\n",
    "    handler = open(filename).read()\n",
    "    soup = Soup(handler, \"lxml\")\n",
    "    extensions = soup.find_all('extension')\n",
    "    for extension in extensions:\n",
    "        ext = str(extension)\n",
    "        if last_name in ext:\n",
    "            return extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCongMemberTag(congMemberExtension):\n",
    "    contents = congMemberExtension.contents\n",
    "    for tag in contents:\n",
    "        tag_str = str(tag)\n",
    "        if 'congmember' in tag_str:\n",
    "            return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getParty(congMemberTag):\n",
    "    return congMemberTag.attrs['party']\n",
    "def getType(congMemberTag):\n",
    "    return congMemberTag.attrs['type']\n",
    "def getAuthorityId(congMemberTag):\n",
    "    return congMemberTag.attrs['authorityid']\n",
    "def getBioGuideId(congMemberTag):\n",
    "    return congMemberTag.attrs['bioguideid']\n",
    "def getState(congMemberTag):\n",
    "    return congMemberTag.attrs['state']\n",
    "def getCongressId(congMemberTag):\n",
    "    return congMemberTag.attrs['congress']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDistrictTag(congMemberExtension):\n",
    "    contents = congMemberExtension.contents\n",
    "    for tag in contents:\n",
    "        tag_str = str(tag)\n",
    "        if 'district' in tag_str:\n",
    "            return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFirstName(congMemberTag):\n",
    "    contents = congMemberTag.contents\n",
    "    name_tags = []\n",
    "    for tag in contents:\n",
    "        tag_str = str(tag)\n",
    "        if 'name' in tag_str:\n",
    "            name_tags += [tag]\n",
    "    try:\n",
    "        first_name = name_tags[1].string.split()[0]\n",
    "    except:\n",
    "        first_name = None\n",
    "    return first_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCongMemberInfoFromMaster(last_name, mods_filename):\n",
    "    info = make_array()\n",
    "    if last_name == 'BORDALLO' or last_name == 'CAPITO':\n",
    "        return getCongMemberInfoFromLocal(last_name, mods_filename)\n",
    "    try:\n",
    "        extension = getCongMemberExtension(master_extensions, last_name)\n",
    "        if extension is None:\n",
    "            return getCongMemberInfoFromLocal(last_name, mods_filename)\n",
    "        congMemberTag = getCongMemberTag(extension)\n",
    "    except:\n",
    "        return getCongMemberInfoFromLocal(last_name, mods_filename)\n",
    "    \n",
    "    \n",
    "    \n",
    "    congMemType = getType(congMemberTag)\n",
    "    district = 'N/A'\n",
    "    if congMemType == 'DELEGATE':\n",
    "        try:\n",
    "            info = getcongMemberInfoFromLocal(last_name, mods_filename)\n",
    "        except:\n",
    "            info = [99999999999999, 'First Name unavailable', last_name, congMemType, 'Party Info Unavailable','state info unavailable', district, 'BioGuideID unavailable', 'CongressID unavailable']\n",
    "    else:\n",
    "        if congMemType == 'REPRESENTATIVE':\n",
    "            try:\n",
    "                district_tag = getDistrictTag(extension)\n",
    "                district = district_tag.string\n",
    "            except:\n",
    "                district = 'N/A'\n",
    "    try:\n",
    "        bioGuideID = getBioGuideId(congMemberTag)\n",
    "    except:\n",
    "        bioGuideID = 99999999999999999\n",
    "    info = [getAuthorityId(congMemberTag), getFirstName(congMemberTag), last_name, congMemType, getParty(congMemberTag), getState(congMemberTag), district, bioGuideID, getCongressId(congMemberTag) ]\n",
    "        \n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getChamber(congMemberTag):\n",
    "    return congMemberTag.attrs['chamber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCongMemberInfoFromLocal(last_name, mods_filename):\n",
    "    print('checking local file')\n",
    "    extension = getCongMemberExtensionFromFile(last_name, mods_filename)\n",
    "    info = make_array()\n",
    "    congMemberTag = getCongMemberTag(extension)\n",
    "    \n",
    "    congMemChamber = getChamber(congMemberTag)\n",
    "    congMemType = 'N/A'\n",
    "    if congMemChamber == 'H':\n",
    "        congMemType = 'REPRESENTATIVE'\n",
    "    elif congMemChamber == 'S':\n",
    "        congMemType = \"SENATOR\"\n",
    "    \n",
    "    district = 'N/A'\n",
    "    if congMemType == 'REPRESENTATIVE':\n",
    "        try:\n",
    "            district_tag = getDistrictTag(extension)\n",
    "            district = district_tag.string\n",
    "        except:\n",
    "            district = 'N/A'\n",
    "            \n",
    "#     info = np.append(info, getAuthorityId(congMemberTag))\n",
    "#     info = np.append(info, getFirstName(congMemberTag))\n",
    "#     info = np.append(info, last_name)\n",
    "#     info = np.append(info, congMemType)\n",
    "#     info = np.append(info, getParty(congMemberTag))\n",
    "#     info = np.append(info, getState(congMemberTag))\n",
    "#     info = np.append(info, district)\n",
    "#     info = np.append(info, getBioGuideId(congMemberTag))\n",
    "#     info = np.append(info, getCongressId(congMemberTag))\n",
    "    try:\n",
    "        authID = getAuthorityId(congMemberTag)\n",
    "    except:\n",
    "        authID = 99999999999999\n",
    "    try:\n",
    "        party = getParty(congMemberTag)\n",
    "    except:\n",
    "        party = 'Party information Unavailable'\n",
    "    try:\n",
    "        state = getState(congMemberTag)\n",
    "    except:\n",
    "        state = 'State Info Unavailable'\n",
    "    try:\n",
    "        bioID = getBioGuideId(congMemberTag)\n",
    "    except:\n",
    "        bioID = 9999999999999999\n",
    "    info = [authID, getFirstName(congMemberTag), last_name, congMemType, party, state, district, bioID, getCongressId(congMemberTag) ]\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with file  1\n",
      "finished with file  2\n",
      "finished with file  3\n",
      "finished with file  4\n",
      "finished with file  5\n",
      "finished with file  6\n",
      "finished with file  7\n",
      "finished with file  8\n",
      "finished with file  9\n",
      "finished with file  10\n",
      "finished with file  11\n",
      "finished with file  12\n",
      "finished with file  13\n",
      "finished with file  14\n",
      "finished with file  15\n",
      "finished with file  16\n",
      "finished with file  17\n",
      "finished with file  18\n",
      "finished with file  19\n",
      "finished with file  20\n",
      "finished with file  21\n",
      "finished with file  22\n",
      "finished with file  23\n",
      "finished with file  24\n",
      "finished with file  25\n",
      "finished with file  26\n",
      "finished with file  27\n",
      "finished with file  28\n",
      "finished with file  29\n",
      "finished with file  30\n",
      "finished with file  31\n",
      "finished with file  32\n",
      "finished with file  33\n",
      "finished with file  34\n",
      "finished with file  35\n",
      "finished with file  36\n",
      "finished with file  37\n",
      "finished with file  38\n",
      "finished with file  39\n",
      "finished with file  40\n",
      "finished with file  41\n",
      "finished with file  42\n",
      "finished with file  43\n",
      "finished with file  44\n",
      "finished with file  45\n",
      "finished with file  46\n",
      "finished with file  47\n",
      "finished with file  48\n",
      "finished with file  51\n",
      "finished with file  54\n",
      "finished with file  59\n",
      "finished with file  62\n",
      "finished with file  64\n",
      "finished with file  67\n",
      "finished with file  68\n",
      "finished with file  73\n",
      "finished with file  75\n",
      "finished with file  76\n",
      "finished with file  77\n",
      "finished with file  78\n",
      "finished with file  79\n",
      "finished with file  80\n",
      "finished with file  81\n",
      "finished with file  83\n",
      "finished with file  84\n",
      "finished with file  85\n",
      "finished with file  86\n",
      "finished with file  87\n",
      "finished with file  88\n",
      "finished with file  89\n",
      "finished with file  90\n",
      "finished with file  91\n",
      "finished with file  92\n",
      "finished with file  95\n",
      "finished with file  96\n",
      "finished with file  98\n",
      "finished with file  100\n",
      "finished with file  102\n",
      "finished with file  104\n",
      "finished with file  105\n",
      "finished with file  106\n",
      "finished with file  107\n",
      "finished with file  108\n",
      "finished with file  109\n",
      "finished with file  110\n",
      "finished with file  111\n",
      "finished with file  112\n",
      "finished with file  113\n",
      "finished with file  114\n",
      "finished with file  116\n",
      "finished with file  117\n",
      "finished with file  118\n",
      "finished with file  119\n",
      "finished with file  120\n",
      "finished with file  121\n",
      "finished with file  122\n",
      "finished with file  124\n",
      "finished with file  126\n",
      "finished with file  127\n",
      "finished with file  128\n",
      "finished with file  131\n",
      "finished with file  134\n",
      "finished with file  138\n",
      "finished with file  141\n",
      "finished with file  142\n",
      "finished with file  143\n",
      "finished with file  144\n",
      "finished with file  145\n",
      "finished with file  146\n",
      "finished with file  147\n",
      "finished with file  148\n",
      "finished with file  149\n",
      "finished with file  150\n",
      "finished with file  152\n",
      "finished with file  153\n",
      "finished with file  166\n",
      "finished with file  167\n",
      "finished with file  181\n",
      "finished with file  182\n",
      "finished with file  184\n",
      "finished with file  186\n",
      "finished with file  188\n",
      "finished with file  189\n",
      "finished with file  190\n",
      "finished with file  191\n",
      "finished with file  192\n",
      "finished with file  193\n",
      "finished with file  194\n",
      "finished with file  195\n",
      "finished with file  196\n",
      "finished with file  197\n",
      "finished with file  198\n",
      "finished with file  199\n",
      "finished with file  200\n",
      "finished with file  201\n",
      "finished with file  202\n",
      "finished with file  203\n",
      "finished with file  204\n",
      "finished with file  205\n",
      "finished with file  206\n",
      "finished with file  207\n",
      "finished with file  208\n",
      "finished with file  209\n",
      "finished with file  210\n",
      "finished with file  211\n",
      "finished with file  212\n",
      "finished with file  213\n",
      "finished with file  214\n",
      "finished with file  215\n",
      "finished with file  216\n",
      "finished with file  217\n",
      "finished with file  218\n",
      "finished with file  219\n",
      "finished with file  220\n",
      "finished with file  221\n",
      "finished with file  222\n",
      "finished with file  223\n",
      "finished with file  224\n",
      "finished with file  226\n",
      "finished with file  229\n",
      "finished with file  230\n",
      "finished with file  232\n",
      "finished with file  234\n",
      "finished with file  235\n",
      "finished with file  237\n",
      "finished with file  238\n",
      "finished with file  240\n",
      "finished with file  245\n",
      "finished with file  247\n",
      "finished with file  248\n",
      "finished with file  249\n",
      "finished with file  252\n",
      "finished with file  254\n",
      "finished with file  255\n",
      "finished with file  256\n",
      "finished with file  258\n",
      "finished with file  259\n",
      "finished with file  260\n",
      "finished with file  261\n",
      "finished with file  264\n",
      "finished with file  265\n",
      "finished with file  266\n",
      "finished with file  267\n",
      "finished with file  268\n",
      "finished with file  269\n",
      "finished with file  270\n",
      "finished with file  271\n",
      "finished with file  272\n",
      "finished with file  274\n",
      "finished with file  275\n",
      "finished with file  277\n",
      "finished with file  278\n",
      "finished with file  280\n",
      "finished with file  282\n",
      "finished with file  284\n",
      "finished with file  285\n",
      "finished with file  287\n",
      "finished with file  289\n",
      "finished with file  291\n",
      "finished with file  293\n",
      "finished with file  294\n",
      "finished with file  295\n",
      "finished with file  299\n",
      "finished with file  301\n",
      "finished with file  313\n",
      "finished with file  322\n",
      "finished with file  331\n",
      "finished with file  333\n",
      "finished with file  335\n",
      "finished with file  336\n",
      "finished with file  338\n",
      "finished with file  340\n",
      "finished with file  346\n",
      "finished with file  355\n",
      "finished with file  361\n",
      "finished with file  382\n",
      "finished with file  387\n",
      "finished with file  394\n",
      "finished with file  395\n",
      "finished with file  396\n",
      "finished with file  397\n",
      "finished with file  398\n",
      "finished with file  399\n",
      "finished with file  401\n",
      "finished with file  403\n",
      "finished with file  405\n",
      "finished with file  407\n",
      "finished with file  408\n",
      "finished with file  409\n",
      "finished with file  410\n",
      "finished with file  412\n",
      "finished with file  414\n",
      "finished with file  416\n",
      "finished with file  417\n",
      "finished with file  418\n",
      "finished with file  420\n",
      "finished with file  437\n",
      "finished with file  439\n",
      "finished with file  455\n",
      "finished with file  456\n",
      "finished with file  464\n",
      "finished with file  465\n",
      "finished with file  467\n",
      "finished with file  468\n",
      "finished with file  470\n",
      "finished with file  471\n",
      "finished with file  472\n",
      "finished with file  473\n",
      "finished with file  474\n",
      "finished with file  475\n",
      "finished with file  476\n",
      "finished with file  477\n",
      "finished with file  478\n",
      "finished with file  479\n",
      "finished with file  480\n",
      "finished with file  481\n",
      "finished with file  482\n",
      "finished with file  483\n",
      "finished with file  484\n",
      "finished with file  485\n",
      "finished with file  487\n",
      "finished with file  488\n",
      "finished with file  489\n",
      "finished with file  490\n",
      "finished with file  492\n",
      "finished with file  493\n",
      "finished with file  494\n",
      "finished with file  495\n",
      "finished with file  496\n",
      "finished with file  497\n",
      "finished with file  499\n",
      "finished with file  500\n",
      "finished with file  501\n",
      "finished with file  502\n",
      "finished with file  503\n",
      "finished with file  504\n",
      "finished with file  505\n",
      "finished with file  506\n",
      "finished with file  507\n",
      "finished with file  508\n",
      "finished with file  509\n",
      "finished with file  511\n",
      "finished with file  512\n",
      "finished with file  516\n",
      "finished with file  517\n",
      "finished with file  519\n",
      "finished with file  525\n",
      "finished with file  526\n",
      "finished with file  531\n",
      "finished with file  533\n",
      "finished with file  548\n",
      "finished with file  550\n",
      "finished with file  551\n",
      "finished with file  569\n",
      "finished with file  571\n",
      "finished with file  572\n",
      "finished with file  573\n",
      "finished with file  575\n",
      "finished with file  602\n",
      "finished with file  603\n",
      "finished with file  605\n",
      "finished with file  606\n",
      "finished with file  608\n",
      "finished with file  610\n",
      "finished with file  612\n",
      "finished with file  614\n",
      "finished with file  615\n",
      "finished with file  616\n",
      "finished with file  618\n",
      "finished with file  620\n",
      "finished with file  622\n",
      "finished with file  623\n",
      "finished with file  624\n",
      "finished with file  625\n",
      "finished with file  626\n",
      "finished with file  628\n",
      "finished with file  630\n",
      "finished with file  632\n",
      "finished with file  633\n",
      "finished with file  635\n",
      "finished with file  637\n",
      "finished with file  639\n",
      "finished with file  641\n",
      "finished with file  642\n",
      "finished with file  643\n",
      "finished with file  644\n",
      "finished with file  645\n",
      "finished with file  646\n",
      "finished with file  647\n",
      "finished with file  648\n",
      "finished with file  649\n",
      "finished with file  650\n",
      "finished with file  651\n",
      "finished with file  652\n",
      "finished with file  653\n",
      "finished with file  654\n",
      "finished with file  655\n",
      "finished with file  656\n",
      "finished with file  657\n",
      "finished with file  658\n",
      "finished with file  659\n",
      "finished with file  660\n",
      "finished with file  661\n",
      "finished with file  662\n",
      "finished with file  663\n",
      "finished with file  664\n",
      "finished with file  665\n",
      "finished with file  666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished with file  668\n",
      "finished with file  669\n",
      "finished with file  671\n",
      "finished with file  672\n",
      "finished with file  673\n",
      "finished with file  678\n",
      "finished with file  680\n",
      "finished with file  682\n",
      "finished with file  683\n",
      "finished with file  684\n",
      "finished with file  686\n",
      "finished with file  687\n",
      "finished with file  688\n",
      "finished with file  689\n",
      "finished with file  690\n",
      "finished with file  691\n",
      "finished with file  692\n",
      "finished with file  694\n",
      "finished with file  696\n",
      "finished with file  698\n",
      "finished with file  700\n",
      "finished with file  702\n",
      "finished with file  703\n",
      "finished with file  708\n",
      "finished with file  709\n",
      "finished with file  711\n",
      "finished with file  712\n",
      "finished with file  714\n",
      "finished with file  716\n",
      "finished with file  717\n",
      "finished with file  719\n",
      "finished with file  721\n",
      "finished with file  724\n",
      "finished with file  726\n",
      "finished with file  728\n",
      "finished with file  730\n",
      "finished with file  732\n",
      "finished with file  735\n",
      "finished with file  737\n",
      "finished with file  739\n",
      "finished with file  741\n",
      "finished with file  742\n",
      "finished with file  760\n",
      "finished with file  761\n",
      "finished with file  762\n",
      "finished with file  763\n",
      "finished with file  764\n",
      "finished with file  765\n",
      "finished with file  766\n",
      "finished with file  767\n",
      "finished with file  798\n",
      "finished with file  799\n",
      "finished with file  802\n",
      "finished with file  816\n",
      "finished with file  818\n",
      "finished with file  820\n",
      "finished with file  821\n",
      "finished with file  823\n",
      "finished with file  825\n",
      "finished with file  827\n",
      "finished with file  829\n",
      "finished with file  830\n",
      "finished with file  831\n",
      "finished with file  832\n",
      "finished with file  833\n",
      "finished with file  834\n",
      "finished with file  835\n",
      "finished with file  836\n",
      "finished with file  837\n",
      "finished with file  839\n",
      "finished with file  841\n",
      "finished with file  843\n",
      "finished with file  844\n",
      "finished with file  845\n",
      "finished with file  846\n",
      "finished with file  847\n",
      "finished with file  848\n",
      "finished with file  849\n",
      "finished with file  850\n",
      "finished with file  851\n",
      "finished with file  852\n",
      "finished with file  853\n",
      "finished with file  854\n",
      "finished with file  855\n",
      "finished with file  856\n",
      "finished with file  858\n",
      "finished with file  859\n",
      "finished with file  860\n",
      "finished with file  862\n",
      "finished with file  864\n",
      "finished with file  866\n",
      "finished with file  868\n",
      "finished with file  870\n",
      "finished with file  872\n",
      "finished with file  959\n",
      "finished with file  960\n",
      "finished with file  961\n",
      "finished with file  962\n",
      "finished with file  968\n",
      "finished with file  969\n",
      "finished with file  971\n",
      "finished with file  973\n",
      "finished with file  974\n",
      "finished with file  975\n",
      "finished with file  977\n",
      "finished with file  979\n",
      "finished with file  981\n",
      "finished with file  983\n",
      "finished with file  984\n",
      "finished with file  986\n",
      "finished with file  988\n",
      "finished with file  990\n",
      "finished with file  992\n",
      "finished with file  994\n",
      "finished with file  995\n",
      "finished with file  996\n",
      "finished with file  999\n",
      "finished with file  1001\n",
      "finished with file  1002\n",
      "finished with file  1003\n",
      "finished with file  1004\n",
      "finished with file  1005\n",
      "finished with file  1006\n",
      "finished with file  1007\n",
      "finished with file  1008\n",
      "finished with file  1009\n",
      "finished with file  1010\n",
      "finished with file  1011\n",
      "finished with file  1012\n",
      "finished with file  1013\n",
      "finished with file  1014\n",
      "finished with file  1015\n",
      "finished with file  1016\n",
      "finished with file  1017\n",
      "finished with file  1018\n",
      "finished with file  1019\n",
      "finished with file  1020\n",
      "finished with file  1021\n",
      "finished with file  1022\n",
      "finished with file  1023\n",
      "finished with file  1024\n",
      "finished with file  1025\n",
      "finished with file  1026\n",
      "finished with file  1027\n",
      "finished with file  1028\n",
      "finished with file  1029\n",
      "finished with file  1030\n",
      "finished with file  1032\n",
      "finished with file  1033\n",
      "finished with file  1035\n",
      "finished with file  1037\n",
      "finished with file  1038\n",
      "finished with file  1039\n",
      "finished with file  1053\n",
      "finished with file  1054\n",
      "finished with file  1058\n",
      "finished with file  1061\n",
      "finished with file  1066\n",
      "finished with file  1067\n",
      "finished with file  1071\n",
      "finished with file  1076\n",
      "finished with file  1086\n",
      "finished with file  1087\n",
      "finished with file  1089\n",
      "finished with file  1091\n",
      "finished with file  1093\n",
      "finished with file  1095\n",
      "finished with file  1097\n",
      "finished with file  1099\n",
      "finished with file  1101\n",
      "finished with file  1102\n",
      "finished with file  1103\n",
      "finished with file  1104\n",
      "finished with file  1105\n",
      "finished with file  1106\n",
      "finished with file  1107\n",
      "finished with file  1108\n",
      "finished with file  1109\n"
     ]
    }
   ],
   "source": [
    "#Populate the Speech Table\n",
    "count = 0\n",
    "for file in os.listdir(\"/Users/cun-yuwang/Desktop/Congress_Records\"): #change directory once we have everything\n",
    "    if file.endswith(\".txt\"):\n",
    "        separated = sep_speech(file)\n",
    "        i = 0\n",
    "        while i < len(separated):\n",
    "            row = make_array()\n",
    "            text = separated[i+1]\n",
    "            text = text.replace('MrPresident', 'Mr. President')\n",
    "            if len(text) > 30:\n",
    "                row = [count, separated[i], 'proceeding_id', 'topic-id', len(text.split()), text, file] \n",
    "                count += 1\n",
    "                speeches = speeches.with_row(row)     \n",
    "            i +=2\n",
    "        count+= 1\n",
    "        print('finished with file ', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>speech_id</th> <th>speaker_id</th> <th>proceeding_id</th> <th>topic_id</th> <th>word_count</th> <th>speech_text</th> <th>file_name</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>48       </td> <td>CORNYN    </td> <td>proceeding_id</td> <td>topic-id</td> <td>2309      </td> <td>Mr.President, many recall that Christmas came a little e ...</td> <td>CREC-2018-01-03-pt2-PgS10.txt  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>49       </td> <td>DURBIN    </td> <td>proceeding_id</td> <td>topic-id</td> <td>25        </td> <td>Mr.President, I ask unanimous consent that the order for ...</td> <td>CREC-2018-01-03-pt2-PgS10.txt  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>51       </td> <td>DURBIN    </td> <td>proceeding_id</td> <td>topic-id</td> <td>893       </td> <td>Mr.President, on September 5 of last year, Attorney Gene ...</td> <td>CREC-2018-01-03-pt2-PgS11.txt  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>52       </td> <td>WHITEHOUSE</td> <td>proceeding_id</td> <td>topic-id</td> <td>23        </td> <td>Mr.President, I ask unanimous consent that the order for ...</td> <td>CREC-2018-01-03-pt2-PgS11.txt  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>54       </td> <td>WHITEHOUSE</td> <td>proceeding_id</td> <td>topic-id</td> <td>2035      </td> <td>Thank you, Mr.President, and happy new year to you.  For ...</td> <td>CREC-2018-01-03-pt2-PgS13.txt  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>55       </td> <td>INHOFE    </td> <td>proceeding_id</td> <td>topic-id</td> <td>22        </td> <td>Mr.President, I ask unanimous consent that the order for ...</td> <td>CREC-2018-01-03-pt2-PgS13.txt  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>56       </td> <td>INHOFE    </td> <td>proceeding_id</td> <td>topic-id</td> <td>25        </td> <td>Mr.President, I ask unanimous consent to speak in mornin ...</td> <td>CREC-2018-01-03-pt2-PgS13.txt  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>57       </td> <td>INHOFE    </td> <td>proceeding_id</td> <td>topic-id</td> <td>1673      </td> <td>Mr.President, I begin by wishing everyone a happy new ye ...</td> <td>CREC-2018-01-03-pt2-PgS13.txt  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>59       </td> <td>INHOFE    </td> <td>proceeding_id</td> <td>topic-id</td> <td>1682      </td> <td>Mr.President, I mentioned that there were three things I ...</td> <td>CREC-2018-01-03-pt2-PgS16-2.txt</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>60       </td> <td>INHOFE    </td> <td>proceeding_id</td> <td>topic-id</td> <td>10        </td> <td>I yield the floor.  The PRESIDING The Senator from       ...</td> <td>CREC-2018-01-03-pt2-PgS16-2.txt</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (573 rows omitted)</p>"
      ],
      "text/plain": [
       "speech_id | speaker_id | proceeding_id | topic_id | word_count | speech_text                                                  | file_name\n",
       "48        | CORNYN     | proceeding_id | topic-id | 2309       | Mr.President, many recall that Christmas came a little e ... | CREC-2018-01-03-pt2-PgS10.txt\n",
       "49        | DURBIN     | proceeding_id | topic-id | 25         | Mr.President, I ask unanimous consent that the order for ... | CREC-2018-01-03-pt2-PgS10.txt\n",
       "51        | DURBIN     | proceeding_id | topic-id | 893        | Mr.President, on September 5 of last year, Attorney Gene ... | CREC-2018-01-03-pt2-PgS11.txt\n",
       "52        | WHITEHOUSE | proceeding_id | topic-id | 23         | Mr.President, I ask unanimous consent that the order for ... | CREC-2018-01-03-pt2-PgS11.txt\n",
       "54        | WHITEHOUSE | proceeding_id | topic-id | 2035       | Thank you, Mr.President, and happy new year to you.  For ... | CREC-2018-01-03-pt2-PgS13.txt\n",
       "55        | INHOFE     | proceeding_id | topic-id | 22         | Mr.President, I ask unanimous consent that the order for ... | CREC-2018-01-03-pt2-PgS13.txt\n",
       "56        | INHOFE     | proceeding_id | topic-id | 25         | Mr.President, I ask unanimous consent to speak in mornin ... | CREC-2018-01-03-pt2-PgS13.txt\n",
       "57        | INHOFE     | proceeding_id | topic-id | 1673       | Mr.President, I begin by wishing everyone a happy new ye ... | CREC-2018-01-03-pt2-PgS13.txt\n",
       "59        | INHOFE     | proceeding_id | topic-id | 1682       | Mr.President, I mentioned that there were three things I ... | CREC-2018-01-03-pt2-PgS16-2.txt\n",
       "60        | INHOFE     | proceeding_id | topic-id | 10         | I yield the floor.  The PRESIDING The Senator from       ... | CREC-2018-01-03-pt2-PgS16-2.txt\n",
       "... (573 rows omitted)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>speech_id</th> <th>speaker_id</th> <th>proceeding_id</th> <th>topic_id</th> <th>word_count</th> <th>speech_text</th> <th>file_name</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>698      </td> <td>BORDALLO  </td> <td>proceeding_id</td> <td>topic-id</td> <td>142       </td> <td>Mr.Speaker, today I am proud to reintroduce my Compact I ...</td> <td>CREC-2018-01-10-pt1-PgH91-7.txt</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "speech_id | speaker_id | proceeding_id | topic_id | word_count | speech_text                                                  | file_name\n",
       "698       | BORDALLO   | proceeding_id | topic-id | 142        | Mr.Speaker, today I am proud to reintroduce my Compact I ... | CREC-2018-01-10-pt1-PgH91-7.txt"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches.where('speaker_id', are.equal_to('BORDALLO'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionairy of unique last names to files\n",
    "distinct_lastname_table = speeches.group('speaker_id')\n",
    "lastname_file_table = speeches.join('speaker_id', distinct_lastname_table, 'speaker_id')\n",
    "lastname_file_table = lastname_file_table.drop('count').drop('speech_id').drop('proceeding_id').drop('topic_id').drop('word_count').drop('speech_text')\n",
    "name_to_xml = {}\n",
    "lastnames = lastname_file_table.column(0)\n",
    "files = lastname_file_table.column(1)\n",
    "count = 0\n",
    "while count < len(lastnames):\n",
    "    name_to_xml[lastnames[count]] = files[count].replace('.txt', '.xml')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALEXANDER\n",
      "ALLEN\n",
      "AMASH\n",
      "BABIN\n",
      "BARRASSO\n",
      "BEYER\n",
      "BIGGS\n",
      "checking local file\n",
      "BILIRAKIS\n",
      "BLUMENAUER\n",
      "BLUMENTHAL\n",
      "BLUNT\n",
      "BOOKER\n",
      "BOOZMAN\n",
      "BORDALLO\n",
      "checking local file\n",
      "BOST\n",
      "BROWN\n",
      "BUCK\n",
      "BUCSHON\n",
      "BUDD\n",
      "BURGESS\n",
      "BURR\n",
      "CAPITO\n",
      "checking local file\n",
      "CARDENAS\n",
      "CARDIN\n",
      "CASSIDY\n",
      "CHABOT\n",
      "CHENEY\n",
      "checking local file\n",
      "CICILLINE\n",
      "COLE\n",
      "COLLINS\n",
      "CONAWAY\n",
      "CORKER\n",
      "CORNYN\n",
      "CORREA\n",
      "checking local file\n",
      "COSTA\n",
      "COURTNEY\n",
      "CRAMER\n",
      "CULBERSON\n",
      "CURTIS\n",
      "checking local file\n",
      "DAINES\n",
      "DAVIDSON\n",
      "checking local file\n",
      "DEMINGS\n",
      "checking local file\n",
      "DEUTCH\n",
      "DONNELLY\n",
      "DONOVAN\n",
      "DUNN\n",
      "checking local file\n",
      "DURBIN\n",
      "EMMER\n",
      "ERNST\n",
      "ESPAILLAT\n",
      "checking local file\n",
      "FITZPATRICK\n",
      "FLAKE\n",
      "FOXX\n",
      "GABBARD\n",
      "GALLAGHER\n",
      "checking local file\n",
      "GARAMENDI\n",
      "GARDNER\n",
      "checking local file\n",
      "GARRETT\n",
      "GIANFORTE\n",
      "checking local file\n",
      "GOHMERT\n",
      "GOMEZ\n",
      "checking local file\n",
      "GOODLATTE\n",
      "GOTTHEIMER\n",
      "checking local file\n",
      "GRIJALVA\n",
      "GUTIERREZ\n",
      "HASTINGS\n",
      "HATCH\n",
      "HECK\n",
      "HEINRICH\n",
      "HILL\n",
      "HIMES\n",
      "HIRONO\n",
      "HOEVEN\n",
      "HOYER\n",
      "HUFFMAN\n",
      "INHOFE\n",
      "ISAKSON\n",
      "JAYAPAL\n",
      "checking local file\n",
      "JEFFRIES\n",
      "KAINE\n",
      "KAPTUR\n",
      "KATKO\n",
      "KEATING\n",
      "KENNEDY\n",
      "KIHUEN\n",
      "checking local file\n",
      "KILDEE\n",
      "KLOBUCHAR\n",
      "LANGEVIN\n",
      "LANKFORD\n",
      "LAWRENCE\n",
      "LEAHY\n",
      "LEE\n",
      "LOFGREN\n",
      "MARINO\n",
      "MARSHALL\n",
      "checking local file\n",
      "MEEHAN\n",
      "MENENDEZ\n",
      "MERKLEY\n",
      "MITCHELL\n",
      "checking local file\n",
      "MORAN\n",
      "MURKOWSKI\n",
      "MURPHY\n",
      "MURRAY\n",
      "NADLER\n",
      "NELSON\n",
      "NEWHOUSE\n",
      "NOEM\n",
      "NORCROSS\n",
      "NUNES\n",
      "OLSON\n",
      "PALAZZO\n",
      "PANETTA\n",
      "checking local file\n",
      "PAULSEN\n",
      "PAYNE\n",
      "PEARCE\n",
      "PELOSI\n",
      "PERDUE\n",
      "PERRY\n",
      "PETERS\n",
      "PITTENGER\n",
      "POCAN\n",
      "POLIS\n",
      "PORTMAN\n",
      "REED\n",
      "REICHERT\n",
      "ROHRABACHER\n",
      "ROKITA\n",
      "ROSEN\n",
      "checking local file\n",
      "ROTHFUS\n",
      "ROUZER\n",
      "RUBIO\n",
      "RUIZ\n",
      "RUPPERSBERGER\n",
      "RUTHERFORD\n",
      "checking local file\n",
      "SABLAN\n",
      "SANDERS\n",
      "SCHAKOWSKY\n",
      "SCHATZ\n",
      "SCHIFF\n",
      "SCHNEIDER\n",
      "checking local file\n",
      "SCHRADER\n",
      "SCHUMER\n",
      "SENSENBRENNER\n",
      "SHAHEEN\n",
      "SHERMAN\n",
      "SMUCKER\n",
      "checking local file\n",
      "SOTO\n",
      "checking local file\n",
      "STEFANIK\n",
      "STEWART\n",
      "SULLIVAN\n",
      "SUOZZI\n",
      "checking local file\n",
      "TAKANO\n",
      "TENNEY\n",
      "checking local file\n",
      "THUNE\n",
      "TIBERI\n",
      "TILLIS\n",
      "TONKO\n",
      "VELA\n",
      "WAGNER\n",
      "WALBERG\n",
      "WALZ\n",
      "WARNER\n",
      "WARREN\n",
      "WENSTRUP\n",
      "WHITEHOUSE\n",
      "YODER\n",
      "YOHO\n",
      "ZELDIN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>speaker_id</th> <th>first_name</th> <th>last_name</th> <th>type</th> <th>party</th> <th>state</th> <th>district</th> <th>bio_guide_id</th> <th>congress_id</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1695      </td> <td>Lamar     </td> <td>ALEXANDER</td> <td>SENATOR       </td> <td>R    </td> <td>TN   </td> <td>N/A     </td> <td>A000360     </td> <td>114        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>2239      </td> <td>Rick      </td> <td>ALLEN    </td> <td>REPRESENTATIVE</td> <td>R    </td> <td>GA   </td> <td>12      </td> <td>A000372     </td> <td>114        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>2029      </td> <td>Justin    </td> <td>AMASH    </td> <td>REPRESENTATIVE</td> <td>R    </td> <td>MI   </td> <td>3       </td> <td>A000367     </td> <td>114        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>2270      </td> <td>Brian     </td> <td>BABIN    </td> <td>REPRESENTATIVE</td> <td>R    </td> <td>TX   </td> <td>36      </td> <td>B001291     </td> <td>114        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>1881      </td> <td>John      </td> <td>BARRASSO </td> <td>SENATOR       </td> <td>R    </td> <td>WY   </td> <td>N/A     </td> <td>B001261     </td> <td>114        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (163 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>speech_id</th> <th>speaker_id</th> <th>proceeding_id</th> <th>topic_id</th> <th>word_count</th> <th>speech_text</th> <th>file_name</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>48       </td> <td>CORNYN    </td> <td>proceeding_id</td> <td>topic-id</td> <td>2309      </td> <td>Mr.President, many recall that Christmas came a little e ...</td> <td>CREC-2018-01-03-pt2-PgS10.txt</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>49       </td> <td>DURBIN    </td> <td>proceeding_id</td> <td>topic-id</td> <td>25        </td> <td>Mr.President, I ask unanimous consent that the order for ...</td> <td>CREC-2018-01-03-pt2-PgS10.txt</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>51       </td> <td>DURBIN    </td> <td>proceeding_id</td> <td>topic-id</td> <td>893       </td> <td>Mr.President, on September 5 of last year, Attorney Gene ...</td> <td>CREC-2018-01-03-pt2-PgS11.txt</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>52       </td> <td>WHITEHOUSE</td> <td>proceeding_id</td> <td>topic-id</td> <td>23        </td> <td>Mr.President, I ask unanimous consent that the order for ...</td> <td>CREC-2018-01-03-pt2-PgS11.txt</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>54       </td> <td>WHITEHOUSE</td> <td>proceeding_id</td> <td>topic-id</td> <td>2035      </td> <td>Thank you, Mr.President, and happy new year to you.  For ...</td> <td>CREC-2018-01-03-pt2-PgS13.txt</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (578 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Populate Speaker Table\n",
    "\n",
    "for name in list(name_to_xml.keys()):\n",
    "    print(name)\n",
    "    row = getCongMemberInfoFromMaster(name, name_to_xml[name])\n",
    "    speakers = speakers.with_row(row)\n",
    "speakers.show(5)\n",
    "speeches.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populating speaker_id column of the speeches table.\n",
    "# newcol = make_array()\n",
    "# names = speeches.column('speaker_id')\n",
    "# for i in np.arange(len(names)):\n",
    "#     newcol = np.append(speakers.where('last_name', are.equal_to(names[i])).column('speaker_id').item(0), newcol)\n",
    "# copy_speeches = speeches.with_column('num_speaker_id', newcol)\n",
    "# copy_speeches.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = speakers.column('last_name')\n",
    "ids = speakers.column('speaker_id')\n",
    "name_to_id = dict(zip(names, ids))\n",
    "name_to_id['CAPITO'] = 1676"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcol = make_array()\n",
    "for name in speeches.sort('speaker_id').column('speaker_id'):\n",
    "    newcol = np.append(name_to_id[name], newcol)\n",
    "speeches = speeches.sort('speaker_id').drop('speaker_id').with_column('speaker_id', np.flip(newcol, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>speech_id</th> <th>proceeding_id</th> <th>topic_id</th> <th>word_count</th> <th>speech_text</th> <th>file_name</th> <th>speaker_id</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>526      </td> <td>proceeding_id</td> <td>topic-id</td> <td>37        </td> <td>I thank the distinguished Presiding Officer, the Senator ...</td> <td>CREC-2018-01-09-pt1-PgS88-2.txt </td> <td>1695      </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>527      </td> <td>proceeding_id</td> <td>topic-id</td> <td>410       </td> <td>Mr.President, on December 1, 2016, Judge Todd Campbell s ...</td> <td>CREC-2018-01-09-pt1-PgS88-2.txt </td> <td>1695      </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>528      </td> <td>proceeding_id</td> <td>topic-id</td> <td>36        </td> <td>Mr.President, I ask for the yeas and nays.  The PRESIDIN ...</td> <td>CREC-2018-01-09-pt1-PgS88-2.txt </td> <td>1695      </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>977      </td> <td>proceeding_id</td> <td>topic-id</td> <td>222       </td> <td>Mr.Speaker, I rise today to thank President Trump for sh ...</td> <td>CREC-2018-01-11-pt1-PgH163-2.txt</td> <td>2239      </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>907      </td> <td>proceeding_id</td> <td>topic-id</td> <td>6963      </td> <td>Mr.Speaker, I have an amendment at the desk.  The SPEAKE ...</td> <td>CREC-2018-01-11-pt1-PgH137-3.txt</td> <td>2029      </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>908      </td> <td>proceeding_id</td> <td>topic-id</td> <td>153       </td> <td>Mr.Speaker, I yield myself such time as I may consume.   ...</td> <td>CREC-2018-01-11-pt1-PgH137-3.txt</td> <td>2029      </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>911      </td> <td>proceeding_id</td> <td>topic-id</td> <td>11        </td> <td>Mr.Speaker, I yield 1 minute to the gentlewoman from Cal ...</td> <td>CREC-2018-01-11-pt1-PgH137-3.txt</td> <td>2029      </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>915      </td> <td>proceeding_id</td> <td>topic-id</td> <td>24        </td> <td>Mr.Speaker, my amendment protects the rights of American ...</td> <td>CREC-2018-01-11-pt1-PgH137-3.txt</td> <td>2029      </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>918      </td> <td>proceeding_id</td> <td>topic-id</td> <td>12        </td> <td>Mr.Speaker, I yield 30 seconds to the gentleman from New ...</td> <td>CREC-2018-01-11-pt1-PgH137-3.txt</td> <td>2029      </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>922      </td> <td>proceeding_id</td> <td>topic-id</td> <td>12        </td> <td>Mr.Speaker, I yield 30 seconds to the gentleman from Cal ...</td> <td>CREC-2018-01-11-pt1-PgH137-3.txt</td> <td>2029      </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (573 rows omitted)</p>"
      ],
      "text/plain": [
       "speech_id | proceeding_id | topic_id | word_count | speech_text                                                  | file_name                        | speaker_id\n",
       "526       | proceeding_id | topic-id | 37         | I thank the distinguished Presiding Officer, the Senator ... | CREC-2018-01-09-pt1-PgS88-2.txt  | 1695\n",
       "527       | proceeding_id | topic-id | 410        | Mr.President, on December 1, 2016, Judge Todd Campbell s ... | CREC-2018-01-09-pt1-PgS88-2.txt  | 1695\n",
       "528       | proceeding_id | topic-id | 36         | Mr.President, I ask for the yeas and nays.  The PRESIDIN ... | CREC-2018-01-09-pt1-PgS88-2.txt  | 1695\n",
       "977       | proceeding_id | topic-id | 222        | Mr.Speaker, I rise today to thank President Trump for sh ... | CREC-2018-01-11-pt1-PgH163-2.txt | 2239\n",
       "907       | proceeding_id | topic-id | 6963       | Mr.Speaker, I have an amendment at the desk.  The SPEAKE ... | CREC-2018-01-11-pt1-PgH137-3.txt | 2029\n",
       "908       | proceeding_id | topic-id | 153        | Mr.Speaker, I yield myself such time as I may consume.   ... | CREC-2018-01-11-pt1-PgH137-3.txt | 2029\n",
       "911       | proceeding_id | topic-id | 11         | Mr.Speaker, I yield 1 minute to the gentlewoman from Cal ... | CREC-2018-01-11-pt1-PgH137-3.txt | 2029\n",
       "915       | proceeding_id | topic-id | 24         | Mr.Speaker, my amendment protects the rights of American ... | CREC-2018-01-11-pt1-PgH137-3.txt | 2029\n",
       "918       | proceeding_id | topic-id | 12         | Mr.Speaker, I yield 30 seconds to the gentleman from New ... | CREC-2018-01-11-pt1-PgH137-3.txt | 2029\n",
       "922       | proceeding_id | topic-id | 12         | Mr.Speaker, I yield 30 seconds to the gentleman from Cal ... | CREC-2018-01-11-pt1-PgH137-3.txt | 2029\n",
       "... (573 rows omitted)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_column = make_array()\n",
    "year_column = make_array()\n",
    "month_column = make_array()\n",
    "day_column = make_array()\n",
    "for file_name in speeches.column('file_name'):\n",
    "    title_column = np.append(find_title(file_name), title_column)\n",
    "    year, month, day = sep_date_from_file(file_name)\n",
    "    year_column = np.append(year, year_column)\n",
    "    month_column = np.append(month, month_column)\n",
    "    day_column = np.append(day, day_column)\n",
    "\n",
    "    title_column = np.flip(title_column, 0)\n",
    "year_column = np.flip(year_column, 0)\n",
    "mont_column = np.flip(month_column, 0)\n",
    "day_column = np.flip(day_column, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speeches = speeches.drop('proceeding_id')\n",
    "speeches = speeches.with_columns('session_title', title_column, 'year', year_column, 'month', month_column, 'day', day_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>speech_id</th> <th>topic_id</th> <th>word_count</th> <th>speech_text</th> <th>file_name</th> <th>speaker_id</th> <th>session_title</th> <th>year</th> <th>month</th> <th>day</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>526      </td> <td>topic-id</td> <td>37        </td> <td>I thank the distinguished Presiding Officer, the Senator ...</td> <td>CREC-2018-01-09-pt1-PgS88-2.txt </td> <td>1695      </td> <td>EXECUTIVE CALENDAR--Continued</td> <td>2018</td> <td>01   </td> <td>09  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>527      </td> <td>topic-id</td> <td>410       </td> <td>Mr.President, on December 1, 2016, Judge Todd Campbell s ...</td> <td>CREC-2018-01-09-pt1-PgS88-2.txt </td> <td>1695      </td> <td>EXECUTIVE CALENDAR--Continued</td> <td>2018</td> <td>01   </td> <td>09  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>528      </td> <td>topic-id</td> <td>36        </td> <td>Mr.President, I ask for the yeas and nays.  The PRESIDIN ...</td> <td>CREC-2018-01-09-pt1-PgS88-2.txt </td> <td>1695      </td> <td>EXECUTIVE CALENDAR--Continued</td> <td>2018</td> <td>01   </td> <td>09  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>977      </td> <td>topic-id</td> <td>222       </td> <td>Mr.Speaker, I rise today to thank President Trump for sh ...</td> <td>CREC-2018-01-11-pt1-PgH163-2.txt</td> <td>2239      </td> <td>SPOTLIGHT ON RURAL AMERICA   </td> <td>2018</td> <td>01   </td> <td>11  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>907      </td> <td>topic-id</td> <td>6963      </td> <td>Mr.Speaker, I have an amendment at the desk.  The SPEAKE ...</td> <td>CREC-2018-01-11-pt1-PgH137-3.txt</td> <td>2029      </td> <td>RAPID DNA ACT OF 2017        </td> <td>2018</td> <td>01   </td> <td>11  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>908      </td> <td>topic-id</td> <td>153       </td> <td>Mr.Speaker, I yield myself such time as I may consume.   ...</td> <td>CREC-2018-01-11-pt1-PgH137-3.txt</td> <td>2029      </td> <td>RAPID DNA ACT OF 2017        </td> <td>2018</td> <td>01   </td> <td>11  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>911      </td> <td>topic-id</td> <td>11        </td> <td>Mr.Speaker, I yield 1 minute to the gentlewoman from Cal ...</td> <td>CREC-2018-01-11-pt1-PgH137-3.txt</td> <td>2029      </td> <td>RAPID DNA ACT OF 2017        </td> <td>2018</td> <td>01   </td> <td>11  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>915      </td> <td>topic-id</td> <td>24        </td> <td>Mr.Speaker, my amendment protects the rights of American ...</td> <td>CREC-2018-01-11-pt1-PgH137-3.txt</td> <td>2029      </td> <td>RAPID DNA ACT OF 2017        </td> <td>2018</td> <td>01   </td> <td>11  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>918      </td> <td>topic-id</td> <td>12        </td> <td>Mr.Speaker, I yield 30 seconds to the gentleman from New ...</td> <td>CREC-2018-01-11-pt1-PgH137-3.txt</td> <td>2029      </td> <td>RAPID DNA ACT OF 2017        </td> <td>2018</td> <td>01   </td> <td>11  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>922      </td> <td>topic-id</td> <td>12        </td> <td>Mr.Speaker, I yield 30 seconds to the gentleman from Cal ...</td> <td>CREC-2018-01-11-pt1-PgH137-3.txt</td> <td>2029      </td> <td>RAPID DNA ACT OF 2017        </td> <td>2018</td> <td>01   </td> <td>11  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (573 rows omitted)</p>"
      ],
      "text/plain": [
       "speech_id | topic_id | word_count | speech_text                                                  | file_name                        | speaker_id | session_title                 | year | month | day\n",
       "526       | topic-id | 37         | I thank the distinguished Presiding Officer, the Senator ... | CREC-2018-01-09-pt1-PgS88-2.txt  | 1695       | EXECUTIVE CALENDAR--Continued | 2018 | 01    | 09\n",
       "527       | topic-id | 410        | Mr.President, on December 1, 2016, Judge Todd Campbell s ... | CREC-2018-01-09-pt1-PgS88-2.txt  | 1695       | EXECUTIVE CALENDAR--Continued | 2018 | 01    | 09\n",
       "528       | topic-id | 36         | Mr.President, I ask for the yeas and nays.  The PRESIDIN ... | CREC-2018-01-09-pt1-PgS88-2.txt  | 1695       | EXECUTIVE CALENDAR--Continued | 2018 | 01    | 09\n",
       "977       | topic-id | 222        | Mr.Speaker, I rise today to thank President Trump for sh ... | CREC-2018-01-11-pt1-PgH163-2.txt | 2239       | SPOTLIGHT ON RURAL AMERICA    | 2018 | 01    | 11\n",
       "907       | topic-id | 6963       | Mr.Speaker, I have an amendment at the desk.  The SPEAKE ... | CREC-2018-01-11-pt1-PgH137-3.txt | 2029       | RAPID DNA ACT OF 2017         | 2018 | 01    | 11\n",
       "908       | topic-id | 153        | Mr.Speaker, I yield myself such time as I may consume.   ... | CREC-2018-01-11-pt1-PgH137-3.txt | 2029       | RAPID DNA ACT OF 2017         | 2018 | 01    | 11\n",
       "911       | topic-id | 11         | Mr.Speaker, I yield 1 minute to the gentlewoman from Cal ... | CREC-2018-01-11-pt1-PgH137-3.txt | 2029       | RAPID DNA ACT OF 2017         | 2018 | 01    | 11\n",
       "915       | topic-id | 24         | Mr.Speaker, my amendment protects the rights of American ... | CREC-2018-01-11-pt1-PgH137-3.txt | 2029       | RAPID DNA ACT OF 2017         | 2018 | 01    | 11\n",
       "918       | topic-id | 12         | Mr.Speaker, I yield 30 seconds to the gentleman from New ... | CREC-2018-01-11-pt1-PgH137-3.txt | 2029       | RAPID DNA ACT OF 2017         | 2018 | 01    | 11\n",
       "922       | topic-id | 12         | Mr.Speaker, I yield 30 seconds to the gentleman from Cal ... | CREC-2018-01-11-pt1-PgH137-3.txt | 2029       | RAPID DNA ACT OF 2017         | 2018 | 01    | 11\n",
       "... (573 rows omitted)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>speaker_id</th> <th>first_name</th> <th>last_name</th> <th>type</th> <th>party</th> <th>state</th> <th>district</th> <th>bio_guide_id</th> <th>congress_id</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2307      </td> <td>Andy      </td> <td>BIGGS    </td> <td>REPRESENTATIVE</td> <td>R    </td> <td>AZ   </td> <td>N/A     </td> <td>B001302     </td> <td>115        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>1723      </td> <td>Madeleine </td> <td>BORDALLO </td> <td>REPRESENTATIVE</td> <td>D    </td> <td>GU   </td> <td>N/A     </td> <td>B001245     </td> <td>115        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>1742      </td> <td>Tom       </td> <td>CORREA   </td> <td>REPRESENTATIVE</td> <td>R    </td> <td>OK   </td> <td>N/A     </td> <td>C001053     </td> <td>115        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>2363      </td> <td>John      </td> <td>CURTIS   </td> <td>REPRESENTATIVE</td> <td>R    </td> <td>UT   </td> <td>N/A     </td> <td>C001114     </td> <td>115        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>2320      </td> <td>Val       </td> <td>DEMINGS  </td> <td>REPRESENTATIVE</td> <td>D    </td> <td>FL   </td> <td>N/A     </td> <td>D000627     </td> <td>115        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>2315      </td> <td>Neal      </td> <td>DUNN     </td> <td>REPRESENTATIVE</td> <td>R    </td> <td>FL   </td> <td>N/A     </td> <td>D000628     </td> <td>115        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>2342      </td> <td>Adriano   </td> <td>ESPAILLAT</td> <td>REPRESENTATIVE</td> <td>D    </td> <td>NY   </td> <td>N/A     </td> <td>E000297     </td> <td>115        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>2355      </td> <td>Mike      </td> <td>GALLAGHER</td> <td>REPRESENTATIVE</td> <td>R    </td> <td>WI   </td> <td>N/A     </td> <td>G000579     </td> <td>115        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>2359      </td> <td>Greg      </td> <td>GIANFORTE</td> <td>REPRESENTATIVE</td> <td>R    </td> <td>MT   </td> <td>N/A     </td> <td>G000584     </td> <td>115        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>2362      </td> <td>Jimmy     </td> <td>GOMEZ    </td> <td>REPRESENTATIVE</td> <td>D    </td> <td>CA   </td> <td>N/A     </td> <td>G000585     </td> <td>115        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (12 rows omitted)</p>"
      ],
      "text/plain": [
       "speaker_id | first_name | last_name | type           | party | state | district | bio_guide_id | congress_id\n",
       "2307       | Andy       | BIGGS     | REPRESENTATIVE | R     | AZ    | N/A      | B001302      | 115\n",
       "1723       | Madeleine  | BORDALLO  | REPRESENTATIVE | D     | GU    | N/A      | B001245      | 115\n",
       "1742       | Tom        | CORREA    | REPRESENTATIVE | R     | OK    | N/A      | C001053      | 115\n",
       "2363       | John       | CURTIS    | REPRESENTATIVE | R     | UT    | N/A      | C001114      | 115\n",
       "2320       | Val        | DEMINGS   | REPRESENTATIVE | D     | FL    | N/A      | D000627      | 115\n",
       "2315       | Neal       | DUNN      | REPRESENTATIVE | R     | FL    | N/A      | D000628      | 115\n",
       "2342       | Adriano    | ESPAILLAT | REPRESENTATIVE | D     | NY    | N/A      | E000297      | 115\n",
       "2355       | Mike       | GALLAGHER | REPRESENTATIVE | R     | WI    | N/A      | G000579      | 115\n",
       "2359       | Greg       | GIANFORTE | REPRESENTATIVE | R     | MT    | N/A      | G000584      | 115\n",
       "2362       | Jimmy      | GOMEZ     | REPRESENTATIVE | D     | CA    | N/A      | G000585      | 115\n",
       "... (12 rows omitted)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers.where('district', are.equal_to('N/A')).where('type', are.equal_to('REPRESENTATIVE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
